{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Feature Extraction\n",
    "\n",
    "The aim of this jupyter notebook is to build upon the data file extraction made by Amanda. The main idea is to use pre\n",
    "existing libraries susch as *scikit-learn*. The main goal is to learn the basics, and train a machine learning model\n",
    "quickly and easily."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First we will extract the data, and save it to a csv.\n",
    "# LAMAO ERLEND. HVOR ER DU? hahahhahahaha\n",
    "# Er hjemmme ðŸ˜… skal fÃ¥ H2O, aka autoML til Ã¥ funke :\n",
    "# Hva er H20? SMUDE! \n",
    "# You go !!\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pylab as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import f_regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 17576 entries, 0 to 17575\n",
      "Data columns (total 47 columns):\n",
      " #   Column                          Non-Null Count  Dtype         \n",
      "---  ------                          --------------  -----         \n",
      " 0   date_calc                       17576 non-null  datetime64[us]\n",
      " 1   date_forecast                   17576 non-null  datetime64[us]\n",
      " 2   absolute_humidity_2m:gm3        17576 non-null  float32       \n",
      " 3   air_density_2m:kgm3             17576 non-null  float32       \n",
      " 4   ceiling_height_agl:m            13657 non-null  float32       \n",
      " 5   clear_sky_energy_1h:J           17576 non-null  float32       \n",
      " 6   clear_sky_rad:W                 17576 non-null  float32       \n",
      " 7   cloud_base_agl:m                15482 non-null  float32       \n",
      " 8   dew_or_rime:idx                 17576 non-null  float32       \n",
      " 9   dew_point_2m:K                  17576 non-null  float32       \n",
      " 10  diffuse_rad:W                   17576 non-null  float32       \n",
      " 11  diffuse_rad_1h:J                17576 non-null  float32       \n",
      " 12  direct_rad:W                    17576 non-null  float32       \n",
      " 13  direct_rad_1h:J                 17576 non-null  float32       \n",
      " 14  effective_cloud_cover:p         17576 non-null  float32       \n",
      " 15  elevation:m                     17576 non-null  float32       \n",
      " 16  fresh_snow_12h:cm               17576 non-null  float32       \n",
      " 17  fresh_snow_1h:cm                17576 non-null  float32       \n",
      " 18  fresh_snow_24h:cm               17576 non-null  float32       \n",
      " 19  fresh_snow_3h:cm                17576 non-null  float32       \n",
      " 20  fresh_snow_6h:cm                17576 non-null  float32       \n",
      " 21  is_day:idx                      17576 non-null  float32       \n",
      " 22  is_in_shadow:idx                17576 non-null  float32       \n",
      " 23  msl_pressure:hPa                17576 non-null  float32       \n",
      " 24  precip_5min:mm                  17576 non-null  float32       \n",
      " 25  precip_type_5min:idx            17576 non-null  float32       \n",
      " 26  pressure_100m:hPa               17576 non-null  float32       \n",
      " 27  pressure_50m:hPa                17576 non-null  float32       \n",
      " 28  prob_rime:p                     17576 non-null  float32       \n",
      " 29  rain_water:kgm2                 17576 non-null  float32       \n",
      " 30  relative_humidity_1000hPa:p     17576 non-null  float32       \n",
      " 31  sfc_pressure:hPa                17576 non-null  float32       \n",
      " 32  snow_density:kgm3               1807 non-null   float32       \n",
      " 33  snow_depth:cm                   17576 non-null  float32       \n",
      " 34  snow_drift:idx                  17576 non-null  float32       \n",
      " 35  snow_melt_10min:mm              17576 non-null  float32       \n",
      " 36  snow_water:kgm2                 17576 non-null  float32       \n",
      " 37  sun_azimuth:d                   17576 non-null  float32       \n",
      " 38  sun_elevation:d                 17576 non-null  float32       \n",
      " 39  super_cooled_liquid_water:kgm2  17576 non-null  float32       \n",
      " 40  t_1000hPa:K                     17576 non-null  float32       \n",
      " 41  total_cloud_cover:p             17576 non-null  float32       \n",
      " 42  visibility:m                    17576 non-null  float32       \n",
      " 43  wind_speed_10m:ms               17576 non-null  float32       \n",
      " 44  wind_speed_u_10m:ms             17576 non-null  float32       \n",
      " 45  wind_speed_v_10m:ms             17576 non-null  float32       \n",
      " 46  wind_speed_w_1000hPa:ms         17576 non-null  float32       \n",
      "dtypes: datetime64[us](2), float32(45)\n",
      "memory usage: 3.3 MB\n"
     ]
    }
   ],
   "source": [
    "train_a = pd.read_parquet('A/train_targets.parquet')\n",
    "X_train_estimated_a = pd.read_parquet('A/X_train_estimated.parquet')\n",
    "X_train_observed_a = pd.read_parquet('A/X_train_observed.parquet')\n",
    "X_test_estimated_a = pd.read_parquet('A/X_test_estimated.parquet')\n",
    "X_train_estimated_a.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_estimated_a = X_train_estimated_a.drop([\"date_calc\"],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_length_matching(train: pd.DataFrame, obs: pd.DataFrame)-> tuple[pd.DataFrame, pd.DataFrame]:\n",
    "    \"\"\"\n",
    "    This function is intended to ensure that both the training data and\n",
    "    the observed data are sorted, and contain the same number of entries. \n",
    "    \"\"\"\n",
    "\n",
    "    # Cut the data frames so that their date match.\n",
    "    obs_feature_test = obs[obs['date_forecast'].isin(train['time'])].sort_values(by=['date_forecast']) # sortert etter datao\n",
    "    \n",
    "    # If only one of them has the date ensure that the other also has the same sorting.\n",
    "    train_feature_test = train[train['time'].isin(obs['date_forecast'])].sort_values(by=['time']) # sortert etter datao\n",
    "\n",
    "    # Would not the rest ensure this?\n",
    "    print('If True same length and time stamps')\n",
    "    print(len(obs_feature_test) == len(train_feature_test))\n",
    "    print(len(obs_feature_test), len(train_feature_test))\n",
    "\n",
    "    return train_feature_test, obs_feature_test\n",
    "\n",
    "def dt64_to_float(dt64):\n",
    "     year = dt64.astype('M8[Y]')\n",
    "     days = (dt64 - year).astype('timedelta64[D]')\n",
    "     year_next = year + np.timedelta64(1, 'Y')\n",
    "     days_of_year = (year_next.astype('M8[D]') - year.astype('M8[D]')).astype('timedelta64[D]')\n",
    "     dt_float = 1970 + year.astype(float) + days / (days_of_year)\n",
    "     return dt_float"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "If True same length and time stamps\n",
      "True\n",
      "34061 34061\n"
     ]
    }
   ],
   "source": [
    "X_total = pd.concat([X_train_estimated_a, X_train_observed_a], axis = 0)\n",
    "y, X = data_length_matching(train_a, X_total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "X['date_forecast'] = dt64_to_float(X['date_forecast'].to_numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removed features: ['air_density_2m:kgm3', 'dew_or_rime:idx', 'elevation:m', 'fresh_snow_1h:cm', 'fresh_snow_3h:cm', 'fresh_snow_6h:cm', 'precip_5min:mm', 'precip_type_5min:idx', 'rain_water:kgm2', 'snow_density:kgm3', 'snow_drift:idx', 'snow_melt_10min:mm', 'snow_water:kgm2', 'super_cooled_liquid_water:kgm2', 'wind_speed_w_1000hPa:ms']\n"
     ]
    }
   ],
   "source": [
    "# y['time'] = dt64_to_float(y['time'].to_numpy())\n",
    "sel = VarianceThreshold(threshold=(.8 * (1 - .8)))\n",
    "sel.fit_transform(X)\n",
    "\n",
    "# Get the mask of selected features (True for selected, False for removed)\n",
    "selected_features_mask = sel.get_support()\n",
    "\n",
    "# Get the names of removed features\n",
    "removed_features = [feature for feature, keep in zip(X.columns, selected_features_mask) if not keep]\n",
    "\n",
    "# Print the names of removed features\n",
    "print(\"Removed features:\", removed_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X.drop(removed_features, axis=1)\n",
    "X = X.fillna(0)\n",
    "# y = y.drop('time', axis=1)\n",
    "y = y['pv_measurement'].ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is x-new\n",
      "[[0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0.]]\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'numpy.ndarray' object has no attribute 'get_support'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\amand\\OneDrive - NTNU\\Documents\\NTNU_studier\\11.semester(YOLO)\\TDT4173-Machine-Learning-Solar-Energy-Production-Forecasting\\data\\feature_extraction.ipynb Cell 10\u001b[0m line \u001b[0;36m5\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/amand/OneDrive%20-%20NTNU/Documents/NTNU_studier/11.semester%28YOLO%29/TDT4173-Machine-Learning-Solar-Energy-Production-Forecasting/data/feature_extraction.ipynb#X22sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mThis is x-new\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/amand/OneDrive%20-%20NTNU/Documents/NTNU_studier/11.semester%28YOLO%29/TDT4173-Machine-Learning-Solar-Energy-Production-Forecasting/data/feature_extraction.ipynb#X22sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39mprint\u001b[39m(X_new)\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/amand/OneDrive%20-%20NTNU/Documents/NTNU_studier/11.semester%28YOLO%29/TDT4173-Machine-Learning-Solar-Energy-Production-Forecasting/data/feature_extraction.ipynb#X22sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m X_new\u001b[39m.\u001b[39;49mget_support()\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/amand/OneDrive%20-%20NTNU/Documents/NTNU_studier/11.semester%28YOLO%29/TDT4173-Machine-Learning-Solar-Energy-Production-Forecasting/data/feature_extraction.ipynb#X22sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m \u001b[39m#+====================================================================================================================+\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/amand/OneDrive%20-%20NTNU/Documents/NTNU_studier/11.semester%28YOLO%29/TDT4173-Machine-Learning-Solar-Energy-Production-Forecasting/data/feature_extraction.ipynb#X22sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m \u001b[39m#| Additional idea: Notice that time of day parameters will probably be provided... Fitting this to a location might  |\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/amand/OneDrive%20-%20NTNU/Documents/NTNU_studier/11.semester%28YOLO%29/TDT4173-Machine-Learning-Solar-Energy-Production-Forecasting/data/feature_extraction.ipynb#X22sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m \u001b[39m#| give us an edge needed to fit a better algorithm for each location...                                              |\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/amand/OneDrive%20-%20NTNU/Documents/NTNU_studier/11.semester%28YOLO%29/TDT4173-Machine-Learning-Solar-Energy-Production-Forecasting/data/feature_extraction.ipynb#X22sZmlsZQ%3D%3D?line=19'>20</a>\u001b[0m \n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/amand/OneDrive%20-%20NTNU/Documents/NTNU_studier/11.semester%28YOLO%29/TDT4173-Machine-Learning-Solar-Energy-Production-Forecasting/data/feature_extraction.ipynb#X22sZmlsZQ%3D%3D?line=20'>21</a>\u001b[0m \u001b[39m# Try implementing this into: Pipeline (1.13.6.)\u001b[39;00m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'numpy.ndarray' object has no attribute 'get_support'"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "X_new = SelectKBest(f_regression, k=5).fit_transform(X, y)\n",
    "print(\"This is x-new\")\n",
    "print(X_new)\n",
    "\n",
    "#+====================================================================================================================+\n",
    "#| Additional idea: Notice that time of day parameters will probably be provided... Fitting this to a location might  |\n",
    "#| give us an edge needed to fit a better algorithm for each location...                                              |\n",
    "#+====================================================================================================================+\n",
    "\n",
    "\n",
    "# This is something \n",
    "# Use some of scikit learn feature extraction functionality.\n",
    "\n",
    "# VarianceThreshold\n",
    "\n",
    "# SelectKBest\n",
    "\n",
    "# Tree-based feature selection\n",
    "\n",
    "# Try implementing this into: Pipeline (1.13.6.)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "basic_machine_learning",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
