{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Can test Kaggle up to 5 times a day \n",
    "\n",
    "#Feature Extraction\n",
    "\n",
    "The aim of this jupyter notebook is to build upon the data file extraction made by Amanda. The main idea is to use pre\n",
    "existing libraries susch as *scikit-learn*. The main goal is to learn the basics, and train a machine learning model\n",
    "quickly and easily."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First we will extract the data, and save it to a csv.\n",
    "# LAMAO ERLEND. HVOR ER DU? hahahhahahaha\n",
    "# Er hjemmme ðŸ˜… skal fÃ¥ H2O, aka autoML til Ã¥ funke :\n",
    "# Hva er H20? SMUDE! \n",
    "# You go !!\n",
    "\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pylab as plt\n",
    "%matplotlib inline\n",
    "\n",
    "\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import f_regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_a = pd.read_parquet('A/train_targets.parquet')\n",
    "X_train_estimated_a = pd.read_parquet('A/X_train_estimated.parquet')\n",
    "X_train_observed_a = pd.read_parquet('A/X_train_observed.parquet')\n",
    "X_test_estimated_a = pd.read_parquet('A/X_test_estimated.parquet')\n",
    "# X_train_estimated_a.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_estimated_a = X_train_estimated_a.drop([\"date_calc\"],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_length_matching(train: pd.DataFrame, obs: pd.DataFrame)-> tuple[pd.DataFrame, pd.DataFrame]:\n",
    "    \"\"\"\n",
    "    This function is intended to ensure that both the training data and\n",
    "    the observed data are sorted, and contain the same number of entries. \n",
    "    \"\"\"\n",
    "\n",
    "    # Cut the data frames so that their date match.\n",
    "    obs_feature_test = obs[obs['date_forecast'].isin(train['time'])].sort_values(by=['date_forecast']) # sortert etter datao\n",
    "    \n",
    "    # If only one of them has the date ensure that the other also has the same sorting.\n",
    "    train_feature_test = train[train['time'].isin(obs['date_forecast'])].sort_values(by=['time']) # sortert etter datao\n",
    "\n",
    "    # Would not the rest ensure this?\n",
    "    print('If True same length and time stamps')\n",
    "    print(len(obs_feature_test) == len(train_feature_test))\n",
    "    print(len(obs_feature_test), len(train_feature_test))\n",
    "\n",
    "    return train_feature_test, obs_feature_test\n",
    "\n",
    "def dt64_to_float(dt64):\n",
    "     year = dt64.astype('M8[Y]')\n",
    "     days = (dt64 - year).astype('timedelta64[D]')\n",
    "     year_next = year + np.timedelta64(1, 'Y')\n",
    "     days_of_year = (year_next.astype('M8[D]') - year.astype('M8[D]')).astype('timedelta64[D]')\n",
    "     dt_float = 1970 + year.astype(float) + days / (days_of_year)\n",
    "     return dt_float"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.13.1. Removing features with low variance\n",
    "#+====================================================================================================================+\n",
    "#| Additional idea: Notice that time of day parameters will probably be provided... Fitting this to a location might  |\n",
    "#| give us an edge needed to fit a better algorithm for each location...                                              |\n",
    "#+====================================================================================================================+\n",
    "\n",
    "\n",
    "This is something \n",
    "Use some of scikit learn feature extraction functionality.\n",
    "\n",
    "* VarianceThreshold\n",
    "\n",
    "* SelectKBest\n",
    "\n",
    "* Tree-based feature selection\n",
    "\n",
    "* Try implementing this into: Pipeline (1.13.6.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If changing original variable -- only run once\n",
    "X_total = pd.concat([X_train_estimated_a, X_train_observed_a], axis = 0)\n",
    "y, X = data_length_matching(train_a, X_total)\n",
    "X['date_forecast'] = dt64_to_float(X['date_forecast'].to_numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removed features: ['air_density_2m:kgm3', 'dew_or_rime:idx', 'elevation:m', 'fresh_snow_1h:cm', 'fresh_snow_3h:cm', 'fresh_snow_6h:cm', 'precip_5min:mm', 'precip_type_5min:idx', 'rain_water:kgm2', 'snow_density:kgm3', 'snow_drift:idx', 'snow_melt_10min:mm', 'snow_water:kgm2', 'super_cooled_liquid_water:kgm2', 'wind_speed_w_1000hPa:ms']\n"
     ]
    }
   ],
   "source": [
    "# y['time'] = dt64_to_float(y['time'].to_numpy())\n",
    "sel = VarianceThreshold(threshold=(.8 * (1 - .8)))\n",
    "sel.fit_transform(X)\n",
    "\n",
    "# Get the mask of selected features (True for selected, False for removed)\n",
    "selected_features_mask = sel.get_support()\n",
    "\n",
    "# Get the names of removed features\n",
    "removed_features = [feature for feature, keep in zip(X.columns, selected_features_mask) if not keep]\n",
    "\n",
    "# Print the names of removed features\n",
    "print(\"Removed features:\", removed_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.13.2. Univariate feature selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If changing original variable -- only run once\n",
    "X = X.drop(removed_features, axis=1) \n",
    "X = X.fillna(0)\n",
    "# y = y.drop('time', axis=1)\n",
    "y = y['pv_measurement'].ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is x-new\n",
      "[[0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "X_new = SelectKBest(f_regression, k=5).fit_transform(X, y)\n",
    "\n",
    "print(\"This is x-new\")\n",
    "print(X_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removed features: ['date_forecast', 'absolute_humidity_2m:gm3', 'ceiling_height_agl:m', 'clear_sky_energy_1h:J', 'clear_sky_rad:W', 'cloud_base_agl:m', 'dew_point_2m:K', 'diffuse_rad:W', 'diffuse_rad_1h:J', 'direct_rad:W', 'direct_rad_1h:J', 'effective_cloud_cover:p', 'fresh_snow_12h:cm', 'fresh_snow_24h:cm', 'is_day:idx', 'is_in_shadow:idx', 'msl_pressure:hPa', 'pressure_100m:hPa', 'pressure_50m:hPa', 'prob_rime:p', 'relative_humidity_1000hPa:p', 'sfc_pressure:hPa', 'snow_depth:cm', 'sun_azimuth:d', 'sun_elevation:d', 't_1000hPa:K', 'total_cloud_cover:p', 'visibility:m', 'wind_speed_10m:ms', 'wind_speed_u_10m:ms', 'wind_speed_v_10m:ms']\n",
      "This is X_new\n",
      "[[0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_selection import SelectKBest, f_regression\n",
    "\n",
    "# Fit the SelectKBest method and transform the data\n",
    "selector = SelectKBest(f_regression, k=5)\n",
    "X_new = selector.fit_transform(X, y)\n",
    "\n",
    "# Get the mask of selected features (True for selected, False for removed)\n",
    "selected_features_mask = selector.get_support()\n",
    "\n",
    "# Get the names of removed features\n",
    "removed_features = [feature for feature, keep in zip(X.columns, ~selected_features_mask)]\n",
    "\n",
    "# Print the names of removed features\n",
    "print(\"Removed features:\", removed_features)\n",
    "\n",
    "# Print the selected features (X_new)\n",
    "print(\"This is X_new\")\n",
    "print(X_new)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removed features: ['date_forecast', 'absolute_humidity_2m:gm3', 'ceiling_height_agl:m', 'clear_sky_energy_1h:J', 'clear_sky_rad:W', 'cloud_base_agl:m', 'dew_point_2m:K', 'diffuse_rad:W', 'diffuse_rad_1h:J', 'direct_rad:W', 'direct_rad_1h:J', 'effective_cloud_cover:p', 'fresh_snow_12h:cm', 'fresh_snow_24h:cm', 'is_day:idx', 'is_in_shadow:idx', 'msl_pressure:hPa', 'pressure_100m:hPa', 'pressure_50m:hPa', 'prob_rime:p', 'relative_humidity_1000hPa:p', 'sfc_pressure:hPa', 'snow_depth:cm', 'sun_azimuth:d', 'sun_elevation:d', 't_1000hPa:K', 'total_cloud_cover:p', 'visibility:m', 'wind_speed_10m:ms', 'wind_speed_u_10m:ms', 'wind_speed_v_10m:ms']\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_selection import SelectKBest, f_regression\n",
    "\n",
    "# Create a SelectKBest instance with the f_regression method and k=5 (to select 5 best features)\n",
    "selector = SelectKBest(f_regression, k=5)\n",
    "\n",
    "# Fit the SelectKBest instance on your data (X and y) to select the best features\n",
    "X_new = selector.fit_transform(X, y)\n",
    "\n",
    "# Get the mask of selected features (True for selected, False for removed)\n",
    "selected_features_mask = selector.get_support()\n",
    "\n",
    "# Get the names of removed features (features not selected)\n",
    "removed_features = [feature for feature, keep in zip(X.columns, ~selected_features_mask)]\n",
    "\n",
    "# Print the names of removed features\n",
    "print(\"Removed features:\", removed_features)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "basic_machine_learning",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
