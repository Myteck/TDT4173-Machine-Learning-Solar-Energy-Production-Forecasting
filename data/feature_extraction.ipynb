{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Feature Extraction\n",
    "\n",
    "The aim of this jupyter notebook is to build upon the data file extraction made by Amanda. The main idea is to use pre\n",
    "existing libraries susch as *scikit-learn*. The main goal is to learn the basics, and train a machine learning model\n",
    "quickly and easily."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First we will extract the data, and save it to a csv.\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pylab as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import f_regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_a = pd.read_parquet('A/train_targets.parquet')\n",
    "X_train_estimated_a = pd.read_parquet('A/X_train_estimated.parquet')\n",
    "X_train_observed_a = pd.read_parquet('A/X_train_observed.parquet')\n",
    "X_test_estimated_a = pd.read_parquet('A/X_test_estimated.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 34085 entries, 0 to 34084\n",
      "Data columns (total 2 columns):\n",
      " #   Column          Non-Null Count  Dtype         \n",
      "---  ------          --------------  -----         \n",
      " 0   time            34085 non-null  datetime64[us]\n",
      " 1   pv_measurement  34085 non-null  float64       \n",
      "dtypes: datetime64[us](1), float64(1)\n",
      "memory usage: 532.7 KB\n"
     ]
    }
   ],
   "source": [
    "print(train_a.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 17576 entries, 0 to 17575\n",
      "Data columns (total 47 columns):\n",
      " #   Column                          Non-Null Count  Dtype         \n",
      "---  ------                          --------------  -----         \n",
      " 0   date_calc                       17576 non-null  datetime64[us]\n",
      " 1   date_forecast                   17576 non-null  datetime64[us]\n",
      " 2   absolute_humidity_2m:gm3        17576 non-null  float32       \n",
      " 3   air_density_2m:kgm3             17576 non-null  float32       \n",
      " 4   ceiling_height_agl:m            13657 non-null  float32       \n",
      " 5   clear_sky_energy_1h:J           17576 non-null  float32       \n",
      " 6   clear_sky_rad:W                 17576 non-null  float32       \n",
      " 7   cloud_base_agl:m                15482 non-null  float32       \n",
      " 8   dew_or_rime:idx                 17576 non-null  float32       \n",
      " 9   dew_point_2m:K                  17576 non-null  float32       \n",
      " 10  diffuse_rad:W                   17576 non-null  float32       \n",
      " 11  diffuse_rad_1h:J                17576 non-null  float32       \n",
      " 12  direct_rad:W                    17576 non-null  float32       \n",
      " 13  direct_rad_1h:J                 17576 non-null  float32       \n",
      " 14  effective_cloud_cover:p         17576 non-null  float32       \n",
      " 15  elevation:m                     17576 non-null  float32       \n",
      " 16  fresh_snow_12h:cm               17576 non-null  float32       \n",
      " 17  fresh_snow_1h:cm                17576 non-null  float32       \n",
      " 18  fresh_snow_24h:cm               17576 non-null  float32       \n",
      " 19  fresh_snow_3h:cm                17576 non-null  float32       \n",
      " 20  fresh_snow_6h:cm                17576 non-null  float32       \n",
      " 21  is_day:idx                      17576 non-null  float32       \n",
      " 22  is_in_shadow:idx                17576 non-null  float32       \n",
      " 23  msl_pressure:hPa                17576 non-null  float32       \n",
      " 24  precip_5min:mm                  17576 non-null  float32       \n",
      " 25  precip_type_5min:idx            17576 non-null  float32       \n",
      " 26  pressure_100m:hPa               17576 non-null  float32       \n",
      " 27  pressure_50m:hPa                17576 non-null  float32       \n",
      " 28  prob_rime:p                     17576 non-null  float32       \n",
      " 29  rain_water:kgm2                 17576 non-null  float32       \n",
      " 30  relative_humidity_1000hPa:p     17576 non-null  float32       \n",
      " 31  sfc_pressure:hPa                17576 non-null  float32       \n",
      " 32  snow_density:kgm3               1807 non-null   float32       \n",
      " 33  snow_depth:cm                   17576 non-null  float32       \n",
      " 34  snow_drift:idx                  17576 non-null  float32       \n",
      " 35  snow_melt_10min:mm              17576 non-null  float32       \n",
      " 36  snow_water:kgm2                 17576 non-null  float32       \n",
      " 37  sun_azimuth:d                   17576 non-null  float32       \n",
      " 38  sun_elevation:d                 17576 non-null  float32       \n",
      " 39  super_cooled_liquid_water:kgm2  17576 non-null  float32       \n",
      " 40  t_1000hPa:K                     17576 non-null  float32       \n",
      " 41  total_cloud_cover:p             17576 non-null  float32       \n",
      " 42  visibility:m                    17576 non-null  float32       \n",
      " 43  wind_speed_10m:ms               17576 non-null  float32       \n",
      " 44  wind_speed_u_10m:ms             17576 non-null  float32       \n",
      " 45  wind_speed_v_10m:ms             17576 non-null  float32       \n",
      " 46  wind_speed_w_1000hPa:ms         17576 non-null  float32       \n",
      "dtypes: datetime64[us](2), float32(45)\n",
      "memory usage: 3.3 MB\n"
     ]
    }
   ],
   "source": [
    "X_train_estimated_a.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"['date_calc'] not found in axis\"",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\isakasa\\OneDrive - NTNU\\Documents\\UNI\\TDT4173 Machine Learning\\group-project\\TDT4173-Machine-Learning-Solar-Energy-Production-Forecasting\\data\\feature_extraction.ipynb Cell 6\u001b[0m line \u001b[0;36m2\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/isakasa/OneDrive%20-%20NTNU/Documents/UNI/TDT4173%20Machine%20Learning/group-project/TDT4173-Machine-Learning-Solar-Energy-Production-Forecasting/data/feature_extraction.ipynb#W5sZmlsZQ%3D%3D?line=24'>25</a>\u001b[0m      dt_float \u001b[39m=\u001b[39m \u001b[39m1970\u001b[39m \u001b[39m+\u001b[39m year\u001b[39m.\u001b[39mastype(\u001b[39mfloat\u001b[39m) \u001b[39m+\u001b[39m days \u001b[39m/\u001b[39m (days_of_year)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/isakasa/OneDrive%20-%20NTNU/Documents/UNI/TDT4173%20Machine%20Learning/group-project/TDT4173-Machine-Learning-Solar-Energy-Production-Forecasting/data/feature_extraction.ipynb#W5sZmlsZQ%3D%3D?line=25'>26</a>\u001b[0m      \u001b[39mreturn\u001b[39;00m dt_float\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/isakasa/OneDrive%20-%20NTNU/Documents/UNI/TDT4173%20Machine%20Learning/group-project/TDT4173-Machine-Learning-Solar-Energy-Production-Forecasting/data/feature_extraction.ipynb#W5sZmlsZQ%3D%3D?line=27'>28</a>\u001b[0m X_train_observed_a \u001b[39m=\u001b[39m X_train_observed_a\u001b[39m.\u001b[39;49mdrop(\u001b[39m\"\u001b[39;49m\u001b[39mdate_calc\u001b[39;49m\u001b[39m\"\u001b[39;49m, axis\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mcolumns\u001b[39;49m\u001b[39m'\u001b[39;49m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/isakasa/OneDrive%20-%20NTNU/Documents/UNI/TDT4173%20Machine%20Learning/group-project/TDT4173-Machine-Learning-Solar-Energy-Production-Forecasting/data/feature_extraction.ipynb#W5sZmlsZQ%3D%3D?line=28'>29</a>\u001b[0m X_total \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mconcat([X_train_estimated_a, X_train_observed_a], axis \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/isakasa/OneDrive%20-%20NTNU/Documents/UNI/TDT4173%20Machine%20Learning/group-project/TDT4173-Machine-Learning-Solar-Energy-Production-Forecasting/data/feature_extraction.ipynb#W5sZmlsZQ%3D%3D?line=30'>31</a>\u001b[0m y, X \u001b[39m=\u001b[39m data_length_matching(train_a, X_total)\n",
      "File \u001b[1;32mc:\\Users\\isakasa\\AppData\\Local\\anaconda3\\envs\\basic_machine_learning\\Lib\\site-packages\\pandas\\core\\frame.py:5347\u001b[0m, in \u001b[0;36mDataFrame.drop\u001b[1;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[0;32m   5199\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mdrop\u001b[39m(\n\u001b[0;32m   5200\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[0;32m   5201\u001b[0m     labels: IndexLabel \u001b[39m|\u001b[39m \u001b[39mNone\u001b[39;00m \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   5208\u001b[0m     errors: IgnoreRaise \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mraise\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m   5209\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m DataFrame \u001b[39m|\u001b[39m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m   5210\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m   5211\u001b[0m \u001b[39m    Drop specified labels from rows or columns.\u001b[39;00m\n\u001b[0;32m   5212\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   5345\u001b[0m \u001b[39m            weight  1.0     0.8\u001b[39;00m\n\u001b[0;32m   5346\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 5347\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49mdrop(\n\u001b[0;32m   5348\u001b[0m         labels\u001b[39m=\u001b[39;49mlabels,\n\u001b[0;32m   5349\u001b[0m         axis\u001b[39m=\u001b[39;49maxis,\n\u001b[0;32m   5350\u001b[0m         index\u001b[39m=\u001b[39;49mindex,\n\u001b[0;32m   5351\u001b[0m         columns\u001b[39m=\u001b[39;49mcolumns,\n\u001b[0;32m   5352\u001b[0m         level\u001b[39m=\u001b[39;49mlevel,\n\u001b[0;32m   5353\u001b[0m         inplace\u001b[39m=\u001b[39;49minplace,\n\u001b[0;32m   5354\u001b[0m         errors\u001b[39m=\u001b[39;49merrors,\n\u001b[0;32m   5355\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\isakasa\\AppData\\Local\\anaconda3\\envs\\basic_machine_learning\\Lib\\site-packages\\pandas\\core\\generic.py:4711\u001b[0m, in \u001b[0;36mNDFrame.drop\u001b[1;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[0;32m   4709\u001b[0m \u001b[39mfor\u001b[39;00m axis, labels \u001b[39min\u001b[39;00m axes\u001b[39m.\u001b[39mitems():\n\u001b[0;32m   4710\u001b[0m     \u001b[39mif\u001b[39;00m labels \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m-> 4711\u001b[0m         obj \u001b[39m=\u001b[39m obj\u001b[39m.\u001b[39;49m_drop_axis(labels, axis, level\u001b[39m=\u001b[39;49mlevel, errors\u001b[39m=\u001b[39;49merrors)\n\u001b[0;32m   4713\u001b[0m \u001b[39mif\u001b[39;00m inplace:\n\u001b[0;32m   4714\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_update_inplace(obj)\n",
      "File \u001b[1;32mc:\\Users\\isakasa\\AppData\\Local\\anaconda3\\envs\\basic_machine_learning\\Lib\\site-packages\\pandas\\core\\generic.py:4753\u001b[0m, in \u001b[0;36mNDFrame._drop_axis\u001b[1;34m(self, labels, axis, level, errors, only_slice)\u001b[0m\n\u001b[0;32m   4751\u001b[0m         new_axis \u001b[39m=\u001b[39m axis\u001b[39m.\u001b[39mdrop(labels, level\u001b[39m=\u001b[39mlevel, errors\u001b[39m=\u001b[39merrors)\n\u001b[0;32m   4752\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m-> 4753\u001b[0m         new_axis \u001b[39m=\u001b[39m axis\u001b[39m.\u001b[39;49mdrop(labels, errors\u001b[39m=\u001b[39;49merrors)\n\u001b[0;32m   4754\u001b[0m     indexer \u001b[39m=\u001b[39m axis\u001b[39m.\u001b[39mget_indexer(new_axis)\n\u001b[0;32m   4756\u001b[0m \u001b[39m# Case for non-unique axis\u001b[39;00m\n\u001b[0;32m   4757\u001b[0m \u001b[39melse\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\isakasa\\AppData\\Local\\anaconda3\\envs\\basic_machine_learning\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:6992\u001b[0m, in \u001b[0;36mIndex.drop\u001b[1;34m(self, labels, errors)\u001b[0m\n\u001b[0;32m   6990\u001b[0m \u001b[39mif\u001b[39;00m mask\u001b[39m.\u001b[39many():\n\u001b[0;32m   6991\u001b[0m     \u001b[39mif\u001b[39;00m errors \u001b[39m!=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mignore\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[1;32m-> 6992\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mKeyError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00mlabels[mask]\u001b[39m.\u001b[39mtolist()\u001b[39m}\u001b[39;00m\u001b[39m not found in axis\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m   6993\u001b[0m     indexer \u001b[39m=\u001b[39m indexer[\u001b[39m~\u001b[39mmask]\n\u001b[0;32m   6994\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdelete(indexer)\n",
      "\u001b[1;31mKeyError\u001b[0m: \"['date_calc'] not found in axis\""
     ]
    }
   ],
   "source": [
    "def data_length_matching(train: pd.DataFrame, obs: pd.DataFrame)-> tuple[pd.DataFrame, pd.DataFrame]:\n",
    "    \"\"\"\n",
    "    This function is intended to ensure that both the training data and\n",
    "    the observed data are sorted, and contain the same number of entries. \n",
    "    \"\"\"\n",
    "\n",
    "    # Cut the data frames so that their date match.\n",
    "    obs_feature_test = obs[obs['date_forecast'].isin(train['time'])].sort_values(by=['date_forecast']) # sortert etter datao\n",
    "    \n",
    "    # If only one of them has the date ensure that the other also has the same sorting.\n",
    "    train_feature_test = train[train['time'].isin(obs['date_forecast'])].sort_values(by=['time']) # sortert etter datao\n",
    "\n",
    "    # Would not the rest ensure this?\n",
    "    print('If True same length and time stamps')\n",
    "    print(len(obs_feature_test) == len(train_feature_test))\n",
    "    print(len(obs_feature_test), len(train_feature_test))\n",
    "\n",
    "    return train_feature_test, obs_feature_test\n",
    "\n",
    "def dt64_to_float(dt64):\n",
    "     year = dt64.astype('M8[Y]')\n",
    "     days = (dt64 - year).astype('timedelta64[D]')\n",
    "     year_next = year + np.timedelta64(1, 'Y')\n",
    "     days_of_year = (year_next.astype('M8[D]') - year.astype('M8[D]')).astype('timedelta64[D]')\n",
    "     dt_float = 1970 + year.astype(float) + days / (days_of_year)\n",
    "     return dt_float\n",
    "\n",
    "X_train_observed_a = X_train_observed_a.drop(\"date_calc\", axis='columns')\n",
    "X_total = pd.concat([X_train_estimated_a, X_train_observed_a], axis = 0)\n",
    "\n",
    "y, X = data_length_matching(train_a, X_total)\n",
    "\n",
    "y['time'] = dt64_to_float(y['time'].to_numpy())\n",
    "\n",
    "X['date_forecast'] = dt64_to_float(X['date_forecast'].to_numpy())\n",
    "X['date_calc'] = dt64_to_float(X['date_calc'].to_numpy())\n",
    "\n",
    "X = X.fillna(0)\n",
    "y = y.drop('time', axis=1)\n",
    "\n",
    "X_new = SelectKBest(f_regression, k=5).fit_transform(X, y)\n",
    "print(\"This is x-new\")\n",
    "print(X_new)\n",
    "\n",
    "#+====================================================================================================================+\n",
    "#| Additional idea: Notice that time of day parameters will probably be provided... Fitting this to a location might  |\n",
    "#| give us an edge needed to fit a better algorithm for each location...                                              |\n",
    "#+====================================================================================================================+\n",
    "\n",
    "\n",
    "\n",
    "# Use some of scikit learn feature extraction functionality.\n",
    "\n",
    "# VarianceThreshold\n",
    "\n",
    "# SelectKBest\n",
    "\n",
    "# Tree-based feature selection\n",
    "\n",
    "# Try implementing this into: Pipeline (1.13.6.)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "basic_machine_learning",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
