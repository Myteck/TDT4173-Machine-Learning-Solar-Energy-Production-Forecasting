{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Feature Extraction\n",
    "\n",
    "The aim of this jupyter notebook is to build upon the data file extraction made by Amanda. The main idea is to use pre\n",
    "existing libraries susch as *scikit-learn*. The main goal is to learn the basics, and train a machine learning model\n",
    "quickly and easily."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Directory: .\n",
      "  File: .DS_Store\n",
      "  File: feature_extraction.ipynb\n",
      "  File: my_first_submission.csv\n",
      "  File: Readme.md\n",
      "  File: read_files.ipynb\n",
      "  File: sample_submission.csv\n",
      "  File: test.csv\n",
      "Directory: .\\A\n",
      "  File: train_targets.parquet\n",
      "  File: X_test_estimated.parquet\n",
      "  File: X_train_estimated.parquet\n",
      "  File: X_train_observed.parquet\n",
      "Directory: .\\B\n",
      "  File: train_targets.parquet\n",
      "  File: X_test_estimated.parquet\n",
      "  File: X_train_estimated.parquet\n",
      "  File: X_train_observed.parquet\n",
      "Directory: .\\C\n",
      "  File: train_targets.parquet\n",
      "  File: X_test_estimated.parquet\n",
      "  File: X_train_estimated.parquet\n",
      "  File: X_train_observed.parquet\n",
      "Directory: .\\pictures\n",
      "Directory: .\\pictures\\plots\n",
      "Directory: .\\pictures\\plots\\A\n",
      "Directory: .\\pictures\\plots\\A\\obs\n",
      "Directory: .\\pictures\\plots\\A\\obs\\box\n",
      "  File: elevationm.png\n",
      "  File: fresh_snow_12hcm.png\n",
      "  File: fresh_snow_1hcm.png\n",
      "  File: fresh_snow_24hcm.png\n",
      "  File: fresh_snow_3hcm.png\n",
      "  File: fresh_snow_6hcm.png\n",
      "  File: is_dayidx.png\n",
      "  File: is_in_shadowidx.png\n",
      "  File: msl_pressurehPa.png\n",
      "  File: precip_5minmm.png\n",
      "  File: precip_type_5minidx.png\n",
      "  File: pressure_100mhPa.png\n",
      "  File: pressure_50mhPa.png\n",
      "  File: prob_rimep.png\n",
      "  File: rain_waterkgm2.png\n",
      "Directory: .\\pictures\\plots\\A\\obs\\line\n",
      "  File: elevationm.png\n",
      "  File: fresh_snow_12hcm.png\n",
      "  File: fresh_snow_1hcm.png\n",
      "  File: fresh_snow_24hcm.png\n",
      "  File: fresh_snow_3hcm.png\n",
      "  File: fresh_snow_6hcm.png\n",
      "  File: is_dayidx.png\n",
      "  File: is_in_shadowidx.png\n",
      "  File: msl_pressurehPa.png\n",
      "  File: precip_5minmm.png\n",
      "  File: precip_type_5minidx.png\n",
      "  File: pressure_100mhPa.png\n",
      "  File: pressure_50mhPa.png\n",
      "  File: prob_rimep.png\n",
      "  File: rain_waterkgm2.png\n",
      "Directory: .\\__pycache__\n",
      "  File: helper.cpython-310.pyc\n",
      "If True same length and time stamps\n",
      "True\n",
      "4394 4394\n",
      "If True same length and time stamps\n",
      "True\n",
      "3601 3601\n",
      "If True same length and time stamps\n",
      "True\n",
      "2930 2930\n",
      "If True same length and time stamps\n",
      "True\n",
      "4394 4394\n",
      "If True same length and time stamps\n",
      "True\n",
      "3601 3601\n",
      "If True same length and time stamps\n",
      "True\n",
      "2930 2930\n"
     ]
    }
   ],
   "source": [
    "# First we will extract the data, and save it to a csv.\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pylab as plt\n",
    "%matplotlib inline\n",
    "\n",
    "pd.set_option('display.max_rows', 200)\n",
    "pd.set_option('display.max_columns', 200)\n",
    "\n",
    "def list_directory_tree_with_os_walk(starting_directory):\n",
    "    for root, directories, files in os.walk(starting_directory):\n",
    "        print(f\"Directory: {root}\")\n",
    "        for file in files:\n",
    "            print(f\"  File: {file}\")\n",
    "\n",
    "list_directory_tree_with_os_walk('.')\n",
    "\n",
    "N_LOCATIONS = 3\n",
    "\n",
    "train_a = pd.read_parquet('A/train_targets.parquet')\n",
    "train_b = pd.read_parquet('B/train_targets.parquet')\n",
    "train_c = pd.read_parquet('C/train_targets.parquet')\n",
    "\n",
    "train = [train_a, train_b, train_c]\n",
    "\n",
    "\n",
    "X_train_estimated_a = pd.read_parquet('A/X_train_estimated.parquet')\n",
    "X_train_estimated_b = pd.read_parquet('B/X_train_estimated.parquet')\n",
    "X_train_estimated_c = pd.read_parquet('C/X_train_estimated.parquet')\n",
    "\n",
    "est = [X_train_estimated_a, X_train_estimated_b, X_train_estimated_c]\n",
    "\n",
    "X_train_observed_a = pd.read_parquet('A/X_train_observed.parquet')\n",
    "X_train_observed_b = pd.read_parquet('B/X_train_observed.parquet')\n",
    "X_train_observed_c = pd.read_parquet('C/X_train_observed.parquet')\n",
    "\n",
    "obs = [X_train_observed_a, X_train_observed_b, X_train_observed_c]\n",
    "\n",
    "X_test_estimated_a = pd.read_parquet('A/X_test_estimated.parquet')\n",
    "X_test_estimated_b = pd.read_parquet('B/X_test_estimated.parquet')\n",
    "X_test_estimated_c = pd.read_parquet('C/X_test_estimated.parquet')\n",
    "\n",
    "test_estimated_sets = [X_test_estimated_a, X_test_estimated_b, X_test_estimated_c]\n",
    "\n",
    "def data_length_matching(train: pd.DataFrame, obs: pd.DataFrame)-> tuple[pd.DataFrame, pd.DataFrame]:\n",
    "    \"\"\"\n",
    "    This function is intended to ensure that both the training data and\n",
    "    the observed data are sorted, and contain the same number of entries. \n",
    "    \"\"\"\n",
    "    \n",
    "    # Cut the data frames so that their date match.\n",
    "    obs_feature_test = obs[obs['date_forecast'].isin(train['time'])].sort_values(by=['date_forecast']) # sortert etter datao\n",
    "    \n",
    "    # If only one of them has the date ensure that the other also has the same sorting.\n",
    "    train_feature_test = train[train['time'].isin(obs['date_forecast'])].sort_values(by=['time']) # sortert etter datao\n",
    "\n",
    "    # Would not the rest ensure this?\n",
    "    print('If True same length and time stamps')\n",
    "    print(len(obs_feature_test) == len(train_feature_test))\n",
    "    print(len(obs_feature_test), len(train_feature_test))\n",
    "\n",
    "    return train_feature_test, obs_feature_test\n",
    "\n",
    "\n",
    "est_train = [None] * N_LOCATIONS\n",
    "\n",
    "obs_train = [None] * N_LOCATIONS\n",
    "\n",
    "for i in range(N_LOCATIONS):\n",
    "    est_train[i], est[i] = data_length_matching(train[i], est[i])\n",
    "\n",
    "for i in range(N_LOCATIONS):\n",
    "    obs_train[i], obs[i] = data_length_matching(train[i], est[i])\n",
    "\n",
    "#========================================================\n",
    "# Should al list be fused together to a GIGA panda frame?\n",
    "#========================================================\n",
    "\n",
    "#============================================================\n",
    "#Adding prefixes to make the different columns more readable.\n",
    "#============================================================\n",
    "\n",
    "LOCATION_PREFIXES = [\"A_\", \"B_\", \"C_\"]\n",
    "\n",
    "for i, prefix in enumerate(LOCATION_PREFIXES):\n",
    "    est_train[i].add_prefix(prefix)\n",
    "    est[i].add_prefix(prefix)\n",
    "\n",
    "for i, prefix in enumerate(LOCATION_PREFIXES):\n",
    "    obs_train[i].add_prefix(prefix)\n",
    "    obs[i].add_prefix(prefix)\n",
    "\n",
    "\n",
    "\n",
    "# Use some of scikit learn feature extraction functionality.\n",
    "\n",
    "# VarianceThreshold\n",
    "\n",
    "# SelectKBest\n",
    "\n",
    "# Tree-based feature selection\n",
    "\n",
    "# Try implementing this into: Pipeline (1.13.6.)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "basic_machine_learning",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
