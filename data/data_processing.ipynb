{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Processing Testing\n",
    "This Jupyter notebook is intended for testing a data processing pipeline. The idea being to organize the functions in its own library. Helping with future testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Processing Tools\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pylab as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_a = pd.read_parquet('A/train_targets.parquet')\n",
    "X_train_estimated_a = pd.read_parquet('A/X_train_estimated.parquet')\n",
    "X_train_observed_a = pd.read_parquet('A/X_train_observed.parquet')\n",
    "X_test_estimated_a = pd.read_parquet('A/X_test_estimated.parquet')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre Processing\n",
    "Removing NaN values, and filling in important holes in the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\isakasa\\AppData\\Local\\Temp\\ipykernel_13724\\3179406313.py:19: FutureWarning: DataFrame.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  X = X.fillna(method=\"backfill\", axis=None)\n"
     ]
    }
   ],
   "source": [
    "def data_length_matching(train: pd.DataFrame, obs: pd.DataFrame)-> tuple[pd.DataFrame, pd.DataFrame]:\n",
    "    \"\"\"\n",
    "    This function is intended to ensure that both the training data and\n",
    "    the observed data are sorted, and contain the same number of entries. \n",
    "    \"\"\"\n",
    "\n",
    "    # Cut the data frames so that their date match.\n",
    "    obs_feature_test = obs[obs['date_forecast'].isin(train['time'])].sort_values(by=['date_forecast'])  # sortert etter datao\n",
    "    # If only one of them has the date ensure that the other also has the same sorting.\n",
    "    train_feature_test = train[train['time'].isin(obs['date_forecast'])].sort_values(by=['time'])       # sortert etter datao\n",
    "\n",
    "    return train_feature_test, obs_feature_test\n",
    "\n",
    "X_train_estimated_a = X_train_estimated_a.drop(\"date_calc\", axis = 1)\n",
    "\n",
    "X = pd.concat([X_train_observed_a, X_train_estimated_a], axis = 0, ignore_index=True)\n",
    "\n",
    "X = X.interpolate(method='linear')\n",
    "X = X.fillna(method=\"backfill\", axis=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Time Dependency\n",
    "The values that we have gotten usually don't have any direct time dependency. This is however wrong all parameters change over time, and the machine learning model having access to what has happened during the previous iteration may be helpfull. This part is only intended to work with time series, and aims to add features such as integrals and derivatives.\n",
    "\n",
    "Main concepts being\n",
    "- Derivative estimates\n",
    "- Double derivative estimates\n",
    "- Integral effect estimates\n",
    "- Double integral estimates\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_derivative_to_df(df: pd.DataFrame, timeStamps: str, measurements: list[str]) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Adds a derivative column to the pandas dataframe. May be used to create time dependency.\n",
    "    \"\"\"\n",
    "\n",
    "    # Sort DataFrame by timestamp\n",
    "    df = df.sort_values(timeStamps) \n",
    "\n",
    "    # Calculate time differences\n",
    "    df['time_diff'] = df[timeStamps].diff()\n",
    "\n",
    "    for measurement in measurements:\n",
    "        # Calculate derivative estimates\n",
    "        df['derivative_' + measurement] = df[measurement].diff() / df['time_diff'].dt.total_seconds()\n",
    "    \n",
    "    df = df.drop('time_diff', axis =  1)\n",
    "\n",
    "    # Since the first element will result in a NaN, we must backfill this one.\n",
    "    df = df.interpolate(method='linear')\n",
    "    df = df.bfill()\n",
    "    \n",
    "    return df\n",
    "\n",
    "def add_double_derivative_to_df(df: pd.DataFrame, timeStamps: str, measurements: list[str]) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Adds a derivative column to the pandas dataframe. May be used to create time dependency.\n",
    "    \"\"\"\n",
    "\n",
    "    # Sort DataFrame by timestamp\n",
    "    df = df.sort_values(timeStamps) \n",
    "\n",
    "    # Calculate time differences\n",
    "    df['time_diff'] = df[timeStamps].diff()\n",
    "\n",
    "    # Calculate derivative estimates\n",
    "    for measurement in measurements:\n",
    "        df['derivative_' + measurement] = df[measurement].diff() / (df['time_diff'].dt.total_seconds()**2)\n",
    "    \n",
    "    df = df.drop('time_diff', axis=1)\n",
    "    \n",
    "    # Since the first element will result in a NaN, we must backfill this one.\n",
    "    df = df.interpolate(method='linear')\n",
    "    df = df.fillna(method=\"backfill\", axis=None)\n",
    "\n",
    "    return df\n",
    "\n",
    "def add_integral_to_df(df: pd.DataFrame, timeStamps: str, measurements: list[str]) -> pd.DataFrame:\n",
    "    \n",
    "    # Sort DataFrame by timestamp\n",
    "    df = df.sort_values(timeStamps)\n",
    "\n",
    "    # Create a new column for the date\n",
    "    df['date'] = df[timeStamps].dt.date\n",
    "\n",
    "    for measurement in measurements:\n",
    "        # Calculate the integral value for each day\n",
    "        df['integral_' + measurement] = df.groupby('date')[measurement].cumsum()\n",
    "    \n",
    "    df = df.drop('date', axis=1)\n",
    "\n",
    "    return df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "absolute_humidity_2m:gm3 \n",
      "0    7.7\n",
      "1    7.7\n",
      "2    7.7\n",
      "3    7.7\n",
      "4    7.7\n",
      "Name: absolute_humidity_2m:gm3, dtype: float32\n",
      "Derivative absolute_humidity_2m:gm3 \n",
      "0    0.0\n",
      "1    0.0\n",
      "2    0.0\n",
      "3    0.0\n",
      "4    0.0\n",
      "Name: derivative_absolute_humidity_2m:gm3, dtype: float64\n",
      "Nan values:  0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\isakasa\\AppData\\Local\\Temp\\ipykernel_13724\\2163152239.py:43: FutureWarning: DataFrame.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  df = df.fillna(method=\"backfill\", axis=None)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        date_forecast  absolute_humidity_2m:gm3  air_density_2m:kgm3  \\\n",
      "0 2019-06-02 22:00:00                       7.7                1.230   \n",
      "1 2019-06-02 22:15:00                       7.7                1.229   \n",
      "2 2019-06-02 22:30:00                       7.7                1.228   \n",
      "3 2019-06-02 22:45:00                       7.7                1.226   \n",
      "4 2019-06-02 23:00:00                       7.7                1.225   \n",
      "\n",
      "   ceiling_height_agl:m  clear_sky_energy_1h:J  clear_sky_rad:W  \\\n",
      "0           1744.900024                    0.0              0.0   \n",
      "1           1734.000000                    0.0              0.0   \n",
      "2           1723.500000                    0.0              0.0   \n",
      "3           1713.400024                    0.0              0.0   \n",
      "4           1703.599976                    0.0              0.0   \n",
      "\n",
      "   cloud_base_agl:m  dew_or_rime:idx  dew_point_2m:K  diffuse_rad:W  ...  \\\n",
      "0       1744.900024              0.0      280.299988            0.0  ...   \n",
      "1       1734.000000              0.0      280.299988            0.0  ...   \n",
      "2       1723.500000              0.0      280.299988            0.0  ...   \n",
      "3       1713.400024              0.0      280.299988            0.0  ...   \n",
      "4       1703.599976              0.0      280.299988            0.0  ...   \n",
      "\n",
      "   derivative_sun_azimuth:d  derivative_sun_elevation:d  \\\n",
      "0                  0.000004               -5.530867e-07   \n",
      "1                  0.000004               -5.530867e-07   \n",
      "2                  0.000004               -4.296294e-07   \n",
      "3                  0.000004               -3.074078e-07   \n",
      "4                  0.000004               -1.802468e-07   \n",
      "\n",
      "   derivative_super_cooled_liquid_water:kgm2  derivative_t_1000hPa:K  \\\n",
      "0                                        0.0            2.469287e-07   \n",
      "1                                        0.0            2.469287e-07   \n",
      "2                                        0.0            2.468910e-07   \n",
      "3                                        0.0            3.703930e-07   \n",
      "4                                        0.0            2.468910e-07   \n",
      "\n",
      "   derivative_total_cloud_cover:p  derivative_visibility:m  \\\n",
      "0                             0.0                 0.000597   \n",
      "1                             0.0                 0.000597   \n",
      "2                             0.0                 0.000623   \n",
      "3                             0.0                 0.000649   \n",
      "4                             0.0                 0.000674   \n",
      "\n",
      "   derivative_wind_speed_10m:ms  derivative_wind_speed_u_10m:ms  \\\n",
      "0                 -1.234570e-07                    0.000000e+00   \n",
      "1                 -1.234570e-07                    0.000000e+00   \n",
      "2                  0.000000e+00                    0.000000e+00   \n",
      "3                 -1.234567e-07                    1.234567e-07   \n",
      "4                  0.000000e+00                    0.000000e+00   \n",
      "\n",
      "   derivative_wind_speed_v_10m:ms  derivative_wind_speed_w_1000hPa:ms  \n",
      "0                    2.469136e-07                                 0.0  \n",
      "1                    2.469136e-07                                 0.0  \n",
      "2                    2.469136e-07                                 0.0  \n",
      "3                    2.469136e-07                                 0.0  \n",
      "4                    2.469136e-07                                 0.0  \n",
      "\n",
      "[5 rows x 91 columns]\n",
      "Nan values:  0\n",
      "        date_forecast  absolute_humidity_2m:gm3  air_density_2m:kgm3  \\\n",
      "0 2019-06-02 22:00:00                       7.7                1.230   \n",
      "1 2019-06-02 22:15:00                       7.7                1.229   \n",
      "2 2019-06-02 22:30:00                       7.7                1.228   \n",
      "3 2019-06-02 22:45:00                       7.7                1.226   \n",
      "4 2019-06-02 23:00:00                       7.7                1.225   \n",
      "\n",
      "   ceiling_height_agl:m  clear_sky_energy_1h:J  clear_sky_rad:W  \\\n",
      "0           1744.900024                    0.0              0.0   \n",
      "1           1734.000000                    0.0              0.0   \n",
      "2           1723.500000                    0.0              0.0   \n",
      "3           1713.400024                    0.0              0.0   \n",
      "4           1703.599976                    0.0              0.0   \n",
      "\n",
      "   cloud_base_agl:m  dew_or_rime:idx  dew_point_2m:K  diffuse_rad:W  ...  \\\n",
      "0       1744.900024              0.0      280.299988            0.0  ...   \n",
      "1       1734.000000              0.0      280.299988            0.0  ...   \n",
      "2       1723.500000              0.0      280.299988            0.0  ...   \n",
      "3       1713.400024              0.0      280.299988            0.0  ...   \n",
      "4       1703.599976              0.0      280.299988            0.0  ...   \n",
      "\n",
      "   integral_sun_azimuth:d  integral_sun_elevation:d  \\\n",
      "0              342.834015                    -3.202   \n",
      "1              689.128052                    -6.852   \n",
      "2             1038.895996                   -10.850   \n",
      "3             1392.146973                   -15.097   \n",
      "4             1748.889038                   -19.490   \n",
      "\n",
      "   integral_super_cooled_liquid_water:kgm2  integral_t_1000hPa:K  \\\n",
      "0                                      0.0            285.899994   \n",
      "1                                      0.0            572.000000   \n",
      "2                                      0.0            858.299988   \n",
      "3                                      0.0           1144.900024   \n",
      "4                                      0.0           1431.699951   \n",
      "\n",
      "   integral_total_cloud_cover:p  integral_visibility:m  \\\n",
      "0                         100.0           39640.101562   \n",
      "1                         200.0           79764.000000   \n",
      "2                         300.0          120392.296875   \n",
      "3                         400.0          161545.906250   \n",
      "4                         500.0          203245.796875   \n",
      "\n",
      "   integral_wind_speed_10m:ms  integral_wind_speed_u_10m:ms  \\\n",
      "0                         3.7                     -3.600000   \n",
      "1                         7.3                     -7.200000   \n",
      "2                        10.9                    -10.799999   \n",
      "3                        14.4                    -14.299999   \n",
      "4                        17.9                    -17.799999   \n",
      "\n",
      "   integral_wind_speed_v_10m:ms  integral_wind_speed_w_1000hPa:ms  \n",
      "0                          -0.8                               0.0  \n",
      "1                          -1.4                               0.0  \n",
      "2                          -1.8                               0.0  \n",
      "3                          -2.0                               0.0  \n",
      "4                          -2.0                               0.0  \n",
      "\n",
      "[5 rows x 91 columns]\n",
      "Nan values:  0\n",
      "96    2019-06-03 22:00:00\n",
      "97    2019-06-03 22:15:00\n",
      "98    2019-06-03 22:30:00\n",
      "99    2019-06-03 22:45:00\n",
      "100   2019-06-03 23:00:00\n",
      "101   2019-06-03 23:15:00\n",
      "102   2019-06-03 23:30:00\n",
      "103   2019-06-03 23:45:00\n",
      "104   2019-06-04 00:00:00\n",
      "105   2019-06-04 00:15:00\n",
      "106   2019-06-04 00:30:00\n",
      "107   2019-06-04 00:45:00\n",
      "108   2019-06-04 01:00:00\n",
      "109   2019-06-04 01:15:00\n",
      "110   2019-06-04 01:30:00\n",
      "111   2019-06-04 01:45:00\n",
      "112   2019-06-04 02:00:00\n",
      "113   2019-06-04 02:15:00\n",
      "114   2019-06-04 02:30:00\n",
      "115   2019-06-04 02:45:00\n",
      "116   2019-06-04 03:00:00\n",
      "117   2019-06-04 03:15:00\n",
      "118   2019-06-04 03:30:00\n",
      "119   2019-06-04 03:45:00\n",
      "Name: date_forecast, dtype: datetime64[us]\n",
      "96     869.000000\n",
      "97     878.299988\n",
      "98     887.599976\n",
      "99     896.900024\n",
      "100    906.200012\n",
      "101    915.500000\n",
      "102    924.799988\n",
      "103    934.200012\n",
      "104      9.400000\n",
      "105     18.799999\n",
      "106     28.299999\n",
      "107     37.900002\n",
      "108     47.599998\n",
      "109     57.200001\n",
      "110     66.599998\n",
      "111     75.900002\n",
      "112     85.099998\n",
      "113     94.400002\n",
      "114    103.800003\n",
      "115    113.300003\n",
      "116    122.900002\n",
      "117    132.500000\n",
      "118    142.199997\n",
      "119    152.000000\n",
      "Name: integral_absolute_humidity_2m:gm3, dtype: float32\n"
     ]
    }
   ],
   "source": [
    "# Testing the functions.\n",
    "\n",
    "# Should make a dummy test set :)\n",
    "timestamps = \"date_forecast\"\n",
    "\n",
    "measurements = list(X.columns.values)\n",
    "measurements.remove(timestamps)\n",
    "\n",
    "\n",
    "X_with_derivatives = add_derivative_to_df(X, timestamps, measurements)\n",
    "\n",
    "print(\"absolute_humidity_2m:gm3 \")\n",
    "print(X_with_derivatives[\"absolute_humidity_2m:gm3\"].head())\n",
    "print(\"Derivative absolute_humidity_2m:gm3 \")\n",
    "print(X_with_derivatives[\"derivative_absolute_humidity_2m:gm3\"].head())\n",
    "\n",
    "# Should add some tests in the spirit of Sverre\n",
    "\n",
    "# Counting NaN values in all columns\n",
    "nan_count = X_with_derivatives.isna().sum()\n",
    "print(\"Nan values: \", sum(nan_count.values))\n",
    "\n",
    "X_with_double_derivatives = add_double_derivative_to_df(X, timestamps, measurements)\n",
    "\n",
    "print(X_with_double_derivatives.head())\n",
    "nan_count = X_with_double_derivatives.isna().sum()\n",
    "print(\"Nan values: \", sum(nan_count.values))\n",
    "\n",
    "\n",
    "\n",
    "X_with_integrals = add_integral_to_df(X, timestamps, measurements)\n",
    "\n",
    "print(X_with_integrals.head())\n",
    "nan_count = X_with_integrals.isna().sum()\n",
    "print(\"Nan values: \", sum(nan_count.values))\n",
    "print(X_with_integrals[timestamps][96:120])\n",
    "print(X_with_integrals[\"integral_absolute_humidity_2m:gm3\"][96:120])\n",
    "# Just return integrals and derivatives!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Spliting Date Time Data\n",
    "The dateTime values are helpfull only so far as doing splitting, and aligning each timestamp. Other than this their usefullness is not that great. Instead we will attempt to split them into a set of values.\n",
    "\n",
    "Such as:\n",
    "- Hour\n",
    "- Date\n",
    "- Month\n",
    "- Year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extracting_time_data(df: pd.DataFrame, timestamps: str) -> pd.DataFrame: \n",
    "    # Extracting components\n",
    "    df['day_of_year'] = df[timestamps].dt.dayofyear\n",
    "    df['month'] = df[timestamps].dt.month\n",
    "    df['year'] = df[timestamps].dt.year\n",
    "    df['hour'] = df[timestamps].dt.hour\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing time data splitter\n",
    "X = extracting_time_data(X, timestamps)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Matching X and y\n",
    "The last steps finding the values that are the corresponding to our measurements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# No need to train on bad values.\n",
    "y = train_a.dropna()\n",
    "\n",
    "# Removing rows that have no matching value, but this is however not that important. The last step before feeding into machine learning algorithm.\n",
    "y, X = data_length_matching(y, X)\n",
    "\n",
    "# Resetting the indexes\n",
    "y = y.reset_index(drop = True)\n",
    "X = X.reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[21492871.29      -4.96584107e-10j  -758202.88096274-5.88566449e+04j\n",
      "  -361982.79979631+3.83510683e+05j ... -1348429.91984673-8.53087795e+05j\n",
      "  -361982.79979631-3.83510683e+05j  -758202.88096274+5.88566449e+04j]\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'plt' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\isakasa\\OneDrive - NTNU\\Documents\\UNI\\TDT4173 Machine Learning\\group-project\\TDT4173-Machine-Learning-Solar-Energy-Production-Forecasting\\data\\data_processing.ipynb Cell 14\u001b[0m line \u001b[0;36m9\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/isakasa/OneDrive%20-%20NTNU/Documents/UNI/TDT4173%20Machine%20Learning/group-project/TDT4173-Machine-Learning-Solar-Energy-Production-Forecasting/data/data_processing.ipynb#W1sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m frequencies \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mfft\u001b[39m.\u001b[39mfftfreq(\u001b[39mlen\u001b[39m(fft_result), \u001b[39m1\u001b[39m\u001b[39m/\u001b[39mfs)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/isakasa/OneDrive%20-%20NTNU/Documents/UNI/TDT4173%20Machine%20Learning/group-project/TDT4173-Machine-Learning-Solar-Energy-Production-Forecasting/data/data_processing.ipynb#W1sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m \u001b[39m# Plot the signal and its FFT\u001b[39;00m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/isakasa/OneDrive%20-%20NTNU/Documents/UNI/TDT4173%20Machine%20Learning/group-project/TDT4173-Machine-Learning-Solar-Energy-Production-Forecasting/data/data_processing.ipynb#W1sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m plt\u001b[39m.\u001b[39mfigure(figsize\u001b[39m=\u001b[39m(\u001b[39m12\u001b[39m, \u001b[39m6\u001b[39m))\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/isakasa/OneDrive%20-%20NTNU/Documents/UNI/TDT4173%20Machine%20Learning/group-project/TDT4173-Machine-Learning-Solar-Energy-Production-Forecasting/data/data_processing.ipynb#W1sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m \u001b[39m# Keep only the dominant frequencies (e.g., top 5)\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/isakasa/OneDrive%20-%20NTNU/Documents/UNI/TDT4173%20Machine%20Learning/group-project/TDT4173-Machine-Learning-Solar-Energy-Production-Forecasting/data/data_processing.ipynb#W1sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m num_components_to_keep \u001b[39m=\u001b[39m \u001b[39m30\u001b[39m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'plt' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "fs = len(y.index)\n",
    "signal = y[\"pv_measurement\"].values\n",
    "\n",
    "fft_result = np.fft.fft(signal)\n",
    "print(fft_result)\n",
    "frequencies = np.fft.fftfreq(len(fft_result), 1/fs)\n",
    "\n",
    "# Plot the signal and its FFT\n",
    "plt.figure(figsize=(12, 6))\n",
    "# Keep only the dominant frequencies (e.g., top 5)\n",
    "num_components_to_keep = 30\n",
    "indices = np.argsort(np.abs(fft_result))[::-1][:num_components_to_keep]\n",
    "\n",
    "# Set all other frequency components to zero\n",
    "fft_result_filtered = np.zeros_like(fft_result)\n",
    "fft_result_filtered[indices] = fft_result[indices]\n",
    "\n",
    "# Compute IFFT\n",
    "ifft_result = np.fft.ifft(fft_result_filtered)\n",
    "\n",
    "fs = 1000  # Sampling frequency\n",
    "\n",
    "plt.subplot(4, 1, 1)\n",
    "plt.plot(y[\"time\"].values, signal)\n",
    "plt.title('Original Signal')\n",
    "plt.xlabel('Time (s)')\n",
    "plt.ylabel('Amplitude')\n",
    "\n",
    "plt.subplot(4, 1, 2)\n",
    "plt.plot(frequencies, np.abs(fft_result))\n",
    "plt.title('FFT of the Signal')\n",
    "plt.xlabel('Frequency (Hz)')\n",
    "plt.ylabel('Magnitude')\n",
    "\n",
    "plt.subplot(4, 1, 3)\n",
    "plt.plot(frequencies, np.abs(fft_result_filtered))\n",
    "plt.title('Filtered FFT')\n",
    "plt.xlabel('Frequency (Hz)')\n",
    "plt.ylabel('Magnitude')\n",
    "\n",
    "plt.subplot(4, 1, 4)\n",
    "plt.plot(y[\"time\"], np.real(ifft_result))\n",
    "plt.title('Reconstructed Signal (IFFT of Filtered FFT)')\n",
    "plt.xlabel('Time (s)')\n",
    "plt.ylabel('Amplitude')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
