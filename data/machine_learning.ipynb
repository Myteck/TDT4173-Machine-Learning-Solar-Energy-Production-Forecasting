{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import data_pipeline as dp\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Machine Learning Model\n",
    "import catboost as cb\n",
    "\n",
    "# Data Processing Tools\n",
    "import pandas as pd\n",
    "\n",
    "# Machine Learning Tools\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from enum import Enum\n",
    " \n",
    "# TODO: ADD NICE MODEL SELECTIONS\n",
    "# TODO: ADD FILTERING TOOLS\n",
    "# TODO: ADD FREQUENCY GENERATION\n",
    "\n",
    "class learner:\n",
    "    def __init__(self, file_paths: list[list[str]], features: list[str] = [], learning_algorithm: str = cb.CatBoostRegressor) -> None:\n",
    "        self.file_paths = file_paths\n",
    "        self.features = features\n",
    "        self.learning_algorithm = learning_algorithm\n",
    "        self.buildings = [\"A\", \"B\", \"C\"]\n",
    "\n",
    "    def create_training_data(self):\n",
    "        list_y = []\n",
    "        list_X = []\n",
    "        list_X_pred = []\n",
    "    \n",
    "        for i, path in enumerate(self.file_paths):\n",
    "            y = pd.read_parquet(path[0])\n",
    "            X_estimated = pd.read_parquet(path[1])\n",
    "            X_observed = pd.read_parquet(path[2])\n",
    "            X_pred = pd.read_parquet(path[3])\n",
    "\n",
    "            # =================  TEST DATA  ================\n",
    "            X_pred = dp.pred_data_processing(X_pred, self.features)\n",
    "            X_pred['building'] = i\n",
    "            print(\"These are XPREDs features\", X_pred.columns.values)\n",
    "            list_X_pred.append(X_pred)\n",
    "\n",
    "            # =================TRAINING DATA================\n",
    "            # Pre-process data\n",
    "            y = y.dropna()\n",
    "            X_estimated = X_estimated.drop(\"date_calc\", axis = 1)\n",
    "            X = pd.concat([X_observed, X_estimated], axis = 0, ignore_index=True)\n",
    "            \n",
    "            # BETTER NAME\n",
    "            X, y= dp.train_data_processing(X, y, self.features)\n",
    "            \n",
    "            # ADD A FUNCTION TO GENERATE BUILDING FEATURE.\n",
    "            X['building'] = i\n",
    "\n",
    "            # Adding the datasets to the lists\n",
    "            list_y.append(y)\n",
    "            list_X.append(X)\n",
    "        \n",
    "        # Add all the lists together. However there is a need to add set\n",
    "        y = pd.concat(list_y, axis= 0)\n",
    "\n",
    "        X = pd.concat(list_X, axis= 0)\n",
    "        X_pred = pd.concat(list_X_pred, axis = 0)\n",
    "\n",
    "        X_train, X_test, self.y_train, self.y_test = train_test_split(X, y, test_size=0.15, shuffle=True)\n",
    "        \n",
    "        # Should probably save their date indexes just in case :/\n",
    "\n",
    "        # Should try scaling later ... :/\n",
    "        self.X_train, self.X_test, self.X_pred = X_train, X_test, X_pred\n",
    "        print(\"These are self XPREDs features\", self.X_pred.columns.values)\n",
    "        return None\n",
    "\n",
    "    def _scale_sets(self, X_train: pd.DataFrame, X_test: pd.DataFrame, X_pred: pd.DataFrame):\n",
    "        \n",
    "        scaler = MinMaxScaler()\n",
    "\n",
    "        unscaled_X_train = X_train.drop('building', axis = 1)\n",
    "        X_train_scaled_values = scaler.fit_transform(unscaled_X_train.values)\n",
    "\n",
    "        X_train_scaled['building'] = X_train['building']\n",
    "\n",
    "        unscaled_X_test = X_test.drop('building', axis = 1)\n",
    "        X_test_scaled = scaler.transform(unscaled_X_test)\n",
    "        X_test_scaled['building'] = X_test['building']\n",
    "        \n",
    "        unscaled_X_pred = X_pred.drop('building', axis = 1)\n",
    "        X_pred_scaled = scaler.transform(unscaled_X_pred)\n",
    "        X_pred_scaled['building'] = X_pred['building']\n",
    "        \n",
    "        return X_train, X_test, X_pred\n",
    "\n",
    "\n",
    "    def fit_model(self) -> None:\n",
    "        \"\"\"\n",
    "        Based on the selected model the class switches between what model is doing the learning. \n",
    "        \"\"\"\n",
    "\n",
    "        #============ SHOULD BE PLACED WITHIN A LIST OF FUNCTIONS ===================#\n",
    "        # Add a function that picks between different models, and processes the data based on this\n",
    "        train_dataset = cb.Pool(self.X_train, self.y_train)\n",
    "\n",
    "        self.model = cb.CatBoostRegressor(loss_function=\"MAE\", logging_level='Silent')\n",
    "\n",
    "        grid = {'iterations': [100, 150, 200],\n",
    "                'learning_rate': [0.03, 0.1],\n",
    "                'depth': [2, 4, 6, 8],\n",
    "                'l2_leaf_reg': [0.2, 0.5, 1, 3]}\n",
    "\n",
    "        self.model.grid_search(grid, train_dataset, verbose=False)\n",
    "        \n",
    "\n",
    "    def get_performance(self) -> None:\n",
    "        pred = self.model.predict(self.X_test)\n",
    "        mae = (mean_absolute_error(self.y_test, pred))\n",
    "        print(\"Mean Abs: {:.2f}\".format(mae))\n",
    "\n",
    "    def predict(self) -> None:\n",
    "        print(self.X_pred.columns.values)\n",
    "        X_pred = self.X_pred.drop('date_forecast', axis = 1)\n",
    "        unformated_pred = self.model.predict(X_pred)\n",
    "        \n",
    "        unformated_pred_df = pd.DataFrame()\n",
    "        unformated_pred_df[\"date_forecast\"] = self.X_pred[\"date_forecast\"]\n",
    "        unformated_pred_df[\"building\"] = self.X_pred[\"building\"]\n",
    "\n",
    "        replace_dict = {0: 'A', 1: 'B', 2: 'C'}\n",
    "\n",
    "         # Use the replace method with the specified column and dictionary\n",
    "        unformated_pred_df[\"building\"] = unformated_pred_df[\"building\"].replace(replace_dict)\n",
    "\n",
    "\n",
    "        unformated_pred_df[\"pv_measurement\"] = pd.Series(unformated_pred)\n",
    "        unformated_pred_df.to_csv(\"sacfadasx.csv\", sep='\\t')\n",
    "\n",
    "        # Should add a save method, so that not all work gets lost :/\n",
    "\n",
    "        pred = self._format_predictions(unformated_pred_df)\n",
    "        self._save_predictions(pred)\n",
    "        \n",
    "\n",
    "    def _format_predictions(self, unformated_pred: pd.DataFrame) -> pd.DataFrame:\n",
    "        \n",
    "        # \n",
    "        to_be_submitted_index = pd.read_csv(\"test.csv\")\n",
    "\n",
    "        #convert the \"time\" column to datetime\n",
    "        to_be_submitted_index[\"time\"] = pd.to_datetime(to_be_submitted_index[\"time\"])\n",
    "        pred = pd.merge(unformated_pred, to_be_submitted_index, how='inner', left_on=['date_forecast', 'building'], right_on=[\"time\", \"location\"])\n",
    "        print(len(unformated_pred.index))\n",
    "        return pred\n",
    "        \n",
    "        return None\n",
    "    def _save_predictions(self, pred: pd.DataFrame)->None:\n",
    "        #Make the index and pv_measurement column into a csv file\n",
    "        pred[[\"id\", \"pv_measurement\"]].rename(columns={\"id\" : \"id\" , \"pv_measurement\" : \"prediction\"}).to_csv(\"model_pred.csv\", index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_paths = [['A/train_targets.parquet', 'A/X_train_estimated.parquet', 'A/X_train_observed.parquet', 'A/X_test_estimated.parquet'],\n",
    "              ['B/train_targets.parquet', 'B/X_train_estimated.parquet', 'B/X_train_observed.parquet', 'B/X_test_estimated.parquet'],\n",
    "              ['C/train_targets.parquet', 'C/X_train_estimated.parquet', 'C/X_train_observed.parquet', 'C/X_test_estimated.parquet']]\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "These are XPREDs features ['diffuse_rad:W' 'direct_rad:W' 'is_in_shadow:idx' 'total_cloud_cover:p'\n",
      " 'sun_elevation:d' 'sun_azimuth:d' 't_1000hPa:K' 'date_forecast'\n",
      " 'building']\n",
      "These are XPREDs features ['diffuse_rad:W' 'direct_rad:W' 'is_in_shadow:idx' 'total_cloud_cover:p'\n",
      " 'sun_elevation:d' 'sun_azimuth:d' 't_1000hPa:K' 'date_forecast'\n",
      " 'building']\n",
      "These are XPREDs features ['diffuse_rad:W' 'direct_rad:W' 'is_in_shadow:idx' 'total_cloud_cover:p'\n",
      " 'sun_elevation:d' 'sun_azimuth:d' 't_1000hPa:K' 'date_forecast'\n",
      " 'building']\n",
      "These are self XPREDs features ['diffuse_rad:W' 'direct_rad:W' 'is_in_shadow:idx' 'total_cloud_cover:p'\n",
      " 'sun_elevation:d' 'sun_azimuth:d' 't_1000hPa:K' 'date_forecast'\n",
      " 'building']\n",
      "Mean Abs: 94.71\n",
      "['diffuse_rad:W' 'direct_rad:W' 'is_in_shadow:idx' 'total_cloud_cover:p'\n",
      " 'sun_elevation:d' 'sun_azimuth:d' 't_1000hPa:K' 'date_forecast'\n",
      " 'building']\n",
      "8640\n"
     ]
    }
   ],
   "source": [
    "features = [] #['diffuse_rad:W', 'direct_rad:W', 'is_in_shadow:idx', 'total_cloud_cover:p', 'sun_elevation:d', 'sun_azimuth:d', 't_1000hPa:K']\n",
    "\n",
    "# Testing the procedure \n",
    "l = learner(file_paths = file_paths, features = features)\n",
    "l.create_training_data()\n",
    "l.fit_model()\n",
    "l.get_performance()\n",
    "l.predict()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "basic_machine_learning",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
